<h2>Education</h2>
<h2>Work Experience</h2>
<h2>Technical Skills</h2>
<div class="content">
<details>
  <summary>GitHub</summary><br>
  <details>
    <summary>First Day on GitHub</summary><br>
    <ul>
      <li><b>Introduction to GitHub:</b> This went over the basics of GitHub. I assigned myself to an issue, and went through processes like creating branches and pull requests, and merging those pull requests.</li>
      <li><b>Communication using Markdown:</b> With the help of this section, I used Markdown formatting to create lists, add headings, include images and links, and apply emphasis to text.</li>
      <li><b>Uploading Your Project to GitHub:</b> For this last section of my first day I prepared a project and uploaded it to a private repository.</li>
    </ul>
   </details>
  <details>
    <summary>First Week on GitHub</summary><br>
    <ul>
      <li><b>GitHub Pages:</b> In this section I created a GitHub Pages site and customized it with blogs and other items using pull requests.</li>
      <li><b>Reviewing pull requests:</b> As part of this module I assigned myself to, commented on, and merged various pull requests, including looking at reviews and applying suggestions.</li>
      <li><b>Managing merge conflicts:</b> In this section I created conflicts and merged pull requests once those conflicts were resolved.</li>
      <li><b>Securing your workflows:</b> For this last section I enabled repository settings and updated the dependcy in order to secure my workflow.</li>
    </ul>
  </details><br>
</details>

<details>
  <summary>Power BI</summary><br>
  <details>
    <summary>Analyzing and Visualizing Data with Power BI</summary><br>
    This is a copy of the syllabus for my Power BI course:<br>
    <img src="EdxCourse.jpeg" alt="Power BI Syllabus"><br><br>

    Here's a breakdown of each chapter:
    <ul>
      <li><b>Introduction:</b> This provided an overview of how Power BI works, including the tools and community that are available for support.</li>
      <li><b>Power BI Desktop Data Transformations:</b> This chapter was about learning to handle data using Power BI Desktop. Specifically I practiced importing data from databases or other sources, editing for certain data types, transforming columns, and pulling only certain data using query parameters.</li>
      <li><b>Power BI Desktop Modeling:</b> In this module I learned about how to manipulate data in the Power BI Desktop. This included creating new calculated columns or measures, filtering data, and learning about how to create and manipulate new data within the application.</li>
      <li><b>Power BI Desktop Visualization:</b> For this section I created and worked with various visualizations including pie charts, treemaps, slicers, maps, waterfalls, scatter plots, gauges, and other elements.</li>
      <li><b>Power BI Service:</b> This section focused on creating and sharing dashboards. Skills I gained included learning how to pin and arrange different elements into a dashboard and publishing that dashboard to the web.</li>
      <li><b>Working with Excel:</b> This module helped to teach me about how Excel and Power BI work together. This included importing Excel data into Power BI, analyzing that data, and being able to pin data directly from Excel into Power BI.</li>
      <li><b>Direct Connectivity:</b> This chapter was about using Power BI to connect to other data sources and extract data to analyze from them. As part of this section, I connected to a SQL database and used data from there to create visualizations and reports.</li>
      <li><b>Developer API:</b> In this chapter I learned that Power BI can integrate with other applications to pull data and create custom visualizations. Specifically, I downloaded visuals such as Sunburst or Radar for this purpose.</li>
      <li><b>Mobile App:</b> In this last module I learned about mobile access to Power BI, and learned how to modify reports and dashboards to be viewed on a mobile device.</li>
    </ul>
  </details>
  <details>
    <summary>Example Dashboard</summary><br>
    As part of my Power BI training I created an example dashboard using the <a href="https://docs.microsoft.com/en-us/power-bi/sample-retail-analysis">Retail Analysis</a> sample dataset from Microsoft. A video of me explaining my dashboard can be found <a href="https://youtu.be/M_BMv8Bf7pQ">here</a>.<br><br>
    My dashboard was creating using data collected from a retail business with two chains. My analyses mostly focused on sales or profit, and I also included one section focusing on business by geographic location and one section comparing newer stores to previously existing stores. <br><br>
    <img src= "Dashboard1.png" alt="Power BI Dashboard"><br>
    <img src= "Dashboard2.png" alt="Power BI Dashboard"><br><br>
    <img src= "Dashboard3.png" alt="Power BI Dashboard"><br><br>
    <img src= "Dashboard4.png" alt="Power BI Dashboard"><br>
  </details><br>
</details>

<details>
  <summary>Linux</summary><br>
  <details>
    <summary>The Linux Community and a Career in Open Source</summary><br>
    <ul>
      <li><b>Linux Evolution and Popular Operating Systems: </b>Gained an understanding of distributions in the Linux operating system and learned about popoular distributions. I also looked at embedded systems and learned more about how Linux has empowered computer workloads in the cloud. Finally, I used the command line to connect to a remote server using SSH, and ran some simple commands such as whoami, ls, pwd, last, uptime, and man.</li>
      <li><b>Major Open-Source Applications: </b>For this section I learned more about open-source applications that use Linux, including browsers, email clients and office applications. We also learned about Linux server applications such as Apache, MySQL and NGINX in addition to a few scripting languages. Lastly we talked about package management, and installed RPM and DEB packages on a remote server. </li>
      <li><b>Open-Source Software and Licensing: </b>This section expanded upon what it means for something to be open source and the different types of open-source licenses that exist.</li>
      <li><b>ICT Skills and Working in Linux: </b>Learned about using a Linux desktop in terms of configuration, web usage, and privacy.I also learned more about accessing the command line by setting up an SSH connection to a remote host via my local macOS terminal, and used commands to determine which distribution I was running.</li>
    </ul>
  </details>
  <details>
    <summary>Finding Your Way on a Linux System</summary><br>
    <ul>
      <li><b>Command Line Basics: </b>Navigating the command line with commands such as pwd, cd, w, and last; setting, locating, and using variables; and how to properly use quotations or other syntax.</li>
      <li><b>Using the Command Line to Get Help: </b>Accessing documentation such as man or info pages to learn more about a commmand or file. </li>
      <li><b>Using Directories and Listing Files: </b>Learning about the Linux filesystem hierarcy in addition to moving around teh filesystem or between directories. Also learned about hidden files, a user's home directory, and absolute and relative paths.</li>
      <li><b>Creating, Moving, and Deleting Files: </b>Learned how to create, move, and delete files and directories. Also looked at how globbing can be used to search for or select certain files or directories.</li>
    </ul>
  </details>
  <details>
    <summary>The Power of the Command Line</summary><br>
    <ul>
      <li><b>Archiving Files on the Command Line: </b>Creating an archive using the command line, and then adding or extracting files from an archive. Also used compression to reduce file sizes.</li>
      <li><b>Searching and Extracting Data from Files: </b>Looked at command line pipes, regular expressions, and using I/O redirection to create files from a command or to read input into a command from a file.</li>
      <li><b>Turning Commands into a Script: </b>Learned about basic shell scripting and common text editors nano and vim.</li>
    </ul>
   </details>
   <details>
    <summary>The Linux Operating System</summary><br>
    <ul>
      <li><b>Choosing an Operating System: </b>Observed the differences between Windows, OS X, and Linux. We also examined the distribution lifecycle to help understand how to a Linux distribution for a specific use case.</li>
      <li><b>Understanding Computer Hardware: </b>Worked to understand how hardware components such as the processor, the motherboard, data storage, and memory work together with the help of drivers. Also used commands including, df, lscpu, lshw, dmidecode, and free to get more information about the hardware.</li>
      <li><b>Where Data is Stored: </b>Knowing where configuration data is stored and where to find process data, in addition to using kernel message to troubleshoot hardware device issues. Also learned about logs and the curl command as a method to find more information or troubleshoot.</li>
      <li><b>Your Computer on the Network: </b>Gained a general understanding of networks, routers, and the internet; how data moves through the network, and how Linux operates on the network. Used DNS configuration and examined network settings using commands such as ipconfig.</li>
    </ul>
   </details>
   <details>
    <summary>Security and File Permissions</summary><br>
    <ul>
      <li><b>Basic Security and Identifying User Types: </b>Compared root and standard users and used the sudo command to elevate permissions for standard users. Also compared standard users to system or service users. </li>
      <li><b>Creating Users and Groups: </b>Learned more about how to manage a Linux system by creating or modifying users and groups. Also looked at user IDs in the Linux operating system and used the command line to determine UID and GID schemes.</li>
      <li><b>Managing File Permissions and Ownership: </b>Modified ownership and modes of files and directories to restrict access to those items.</li>
      <li><b>Special Directories and Files: </b>Created temporary files and looked at the differences between directories depending on file holding needs. Also used symbolic links to reference files or directories, and learned how to work with those when filenames change.</li>
    </ul>
   </details>
   <details>
    <summary>Linux Certification</summary><br>
    <img src= "doc.png" alt="Linux Certification"><br>
   </details>
   <details>
     <summary>Algo VPN with Digital Ocean</summary><br>
    After completing my Linux Essentials training, I used Ubuntu via VirtualBox to set up an Algo VPN with Digital Ocean. I also used WireGuard to activate and deactivate the VPN. The following image shows my IP address before activating the VPN, and then after. You can see that the IP address in the second image matches the IP address shown for my Digital Ocean droplet.<br><br>
    <img src="vpn_proof.png"><br>
  </details><br>
</details>
  
<details>
  <summary>AWS</summary><br>
    <details>
    <summary>Managing AWS Access with Users, Groups, and Roles</summary><br>
    Covered AWS Identity and Access Management or IAM, and learned how to set up and configure users, groups, roles, and policies in order to control who has access to AWS resources.<br><br>
    </details>
  <details>
    <summary>Networking Services and Connectivity</summary><br>
    Learned about how AWS operates as a global system with worldwide infrastructure. Also covered Virtual Private Clouds, or VPCs, and created a basic VPC which included configuring internet gateways, routing tables, network access control lists, and establishing subnets across multiple Availability Zones.<br><br>
    </details>
    <details>
    <summary>Compute Services</summary><br>
    For this section I configured a Linux EC2 (Elastic Cloud Compute) instance, which I continued to from my Mac terminal via SSH. Configuring this instance included setting up security rules for inbound and outbound traffic. I also learned how to connect to a Windows EC2 instance using Putty.<br><br>
    </details>
    <details>
    <summary>Storage Services</summary><br>
    This section covered Amazon S3, or Amazon Simple Storage Service. I learned about the different storage classes that are available depending on user needs, and created both public and private Amazon S3 buckets to store folders and objects in. I also enabled versions to ensure that various versions of the same bucket would be available. Finally, I created a basic Amazon S3 Lifecycle Policy to control how long an object stays in a specific storage class.<br><br>
    </details>
    <details>
    <summary>Database Services</summary><br>
    In this section I learned about the database services AWS offers such as Amazon RDS (Relational Database Services) and DynamoDB. As part of a lab I created a MySQL compatible Aurora RDS Database. This process included verifying security groups, network access control lists, and route tables to allow for communication between a private and public subnet, and creating a EC2 instance in order to connect to the RDS database.<br><br>
    </details>
    <details>
    <summary>Monitoring, Alerts, and Notifications</summary><br>
    This section worked with with Amazon SNS, or Simple Notification Service, and I learned how Amazon SNS can be used to push messages out from publishers to subscribers. I also learned about AWS management tools, namely CloudWatch, which can be used to monitor elements within an AWS account. As part of a lab, I created a new SNS topic, and then created a CloudWatch Events rule to prompt that topic and provide an email notification whenever there was a state change to an EC2 instance. This section also discussed CloudTrail for the purpose of tracking actions on an AWS account.<br><br>
    </details>
    <details>
    <summary>Load Balancing, Elasticity, and Scalability</summary><br>
    This section touched on Amazon's Electric Load Balancer (ELB) which can be applied to evenly distribute traffic between EC2 instances, Auto Scaling, which can be used to increase or reduce the number of EC2 instances needed, and Route 53, which is a cloud Domain Name System service. As part of a lab I created and configured an application load balancer, including creating an auto scaling group using my own launch configuration, which I tested with an alias record. <br><br>
    </details>
    <details>
    <summary>Serverless Compute</summary><br>
    This section covered Lambda, which lets you run code without having to manage or configure servers. As part of this training, I created a basic Lambda function used to shut down an EC2 instance.<br><br>
    </details>
    <details>
    <summary>AWS Certification</summary><br>
    <img src= "awscert.png" alt="AWS Certification"><br>
   </details>
   <details>
    <summary>Algo VPN and OpenVPN with AWS</summary><br>
    After completing the AWS Essentials training, I set up an EC2 instance on AWS and used that to run a VPN using both Algo VPN and OpenVPN.<br><br>
    <img src= "awsalgo.png" alt="AWS Algo VPN"><br>
    <img src= "awsopenvpn.PNG" alt="AWS OpenVPN"><br>
   </details><br>
 </details>

<details>
  <summary>PowerShell</summary><br>
    <details>
    <summary>Discovery and Getting Help</summary><br>
    For this first training segment, I learned how Linux skills can transfer into PowerShell. Like with Linux, PowerShell allows you to search for different commands, or cmdlets, using commands like "get-help," so there is no need to memorize the thousands of commands that exist. You can also modify "get-help" with commands like "-Detailed" or "-ShowWindow," which provides you more information and examples of how different cmdlets work. Finally, we learned about cmdlet syntax and how to use parameteres and arguments<br><br>
    </details>
    <details>
    <summary>Extending Your Capabilities with PowerShell</summary><br>
    In this section I learned about using snap-ins and modules in PowerShell. This included learning how to find and install different modules using methods such as dynamic importing, in addition to looking for modules using Microsoft repositories or a local repository. <br><br>
    </details>
    <details>
    <summary>Using the Power of the Pipeline</summary><br>
    This section explained how you can used the pipeline to string various commands together. One application of this pipleine is that you can work with CSV and XML files and import or export them from your existing information. You can also compare files to the processing you currently have. Finally, you can convert information into HTML webpages. <br><br>
    </details>
    <details>
    <summary>Getting More out of Objects</summary><br>
    In this section I learned about PowerShell objects and how to get more information on them using cmdlets like "Get-Member." You can also sort the information you receive on objects using cmdlets like "Sort-Object," or you can create filters for that data. In addition, you can use cmdlets to create your own properties or rename the properties already shown in PowerShell.<br><br>
    </details>
  <details>
    <summary>Scripts and Automation</summary><br>
    This section covered how to use PowerShell Integrated Scripting Environment to record commands you've built. Just like when writing commands, you can include parameters when scripting to focus on the items that matter to you. One way I learned how to store this scripts is through variables, which is a type of temporary storage on PowerShell. Finally, it can be helpful to include comments in your scripts to act as a guide for when you want to use those commands later. <br><br>
    </details>
    <details>
    <summary>Scalable Management with PowerShell Remoting</summary><br>
    This last section introduced PowerShell remoting, starting with enabling PowerShell remoting so you can use it on your machine. Powershell remoting can be used in a one-to-one capacity between devices, or you can can scale to a one-to-may relationship, and operate many machines using a single device. <br><br>
    </details>
   <details>
    <summary>PowerShell Essentials Certification</summary><br>
    <br>
    <img src= "PowerShellCert.png" alt="PowerShell Certification"><br>
   </details><br>
</details>
</div>
